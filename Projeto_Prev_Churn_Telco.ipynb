{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d045d4ab",
   "metadata": {},
   "source": [
    "# üìä Projeto de Previs√£o de Churn - Telco Customer Churn Dataset\n",
    "Este notebook realiza uma an√°lise explorat√≥ria e previs√£o de churn usando dados reais de clientes de telecomunica√ß√µes. Inclui limpeza, modelagem e visualiza√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√£o das bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Upload do dataset (Google Colab)\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Carregamento dos dados\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "print(\"Shape do dataset:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839ef16c",
   "metadata": {},
   "source": [
    "## üîç An√°lise Explorat√≥ria (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(\"\\nTaxa de Churn:\")\n",
    "print(df['Churn'].value_counts(normalize=True))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Churn', data=df)\n",
    "plt.title('Distribui√ß√£o de Churn')\n",
    "plt.show()\n",
    "\n",
    "# Converter TotalCharges temporariamente para num√©rico para EDA\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Histogramas\n",
    "for col in ['tenure', 'MonthlyCharges', 'TotalCharges']:\n",
    "    plt.figure()\n",
    "    sns.histplot(df[col].dropna(), kde=True)\n",
    "    plt.title(f'Distribui√ß√£o de {col}')\n",
    "    plt.show()\n",
    "\n",
    "# Churn por tipo de contrato\n",
    "sns.countplot(x='Contract', hue='Churn', data=df)\n",
    "plt.title('Churn por Tipo de Contrato')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd424b9c",
   "metadata": {},
   "source": [
    "## üßπ Limpeza e Prepara√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd2476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover coluna irrelevante\n",
    "df.drop('customerID', axis=1, inplace=True)\n",
    "\n",
    "# Converter TotalCharges e preencher nulos\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)\n",
    "\n",
    "# Converter alvo e vari√°veis categ√≥ricas\n",
    "df['Churn'] = LabelEncoder().fit_transform(df['Churn'])\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        if df[col].nunique() == 2:\n",
    "            df[col] = LabelEncoder().fit_transform(df[col])\n",
    "        else:\n",
    "            df = pd.get_dummies(df, columns=[col], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b6057a",
   "metadata": {},
   "source": [
    "## ü§ñ Treinamento dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2536f24",
   "metadata": {},
   "source": [
    "## üìà Avalia√ß√£o e Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb804f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Regress√£o Log√≠stica ===\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "print(\"AUC:\", roc_auc_score(y_test, log_model.predict_proba(X_test)[:,1]))\n",
    "\n",
    "print(\"\\n=== Random Forest ===\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"AUC:\", roc_auc_score(y_test, rf_model.predict_proba(X_test)[:,1]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
    "ax[0].set_title('Matriz de Confus√£o - Random Forest')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, rf_model.predict_proba(X_test)[:,1])\n",
    "ax[1].plot(fpr, tpr, label=f'ROC (AUC = {roc_auc_score(y_test, rf_model.predict_proba(X_test)[:,1]):.3f})')\n",
    "ax[1].plot([0,1],[0,1],'--')\n",
    "ax[1].legend()\n",
    "plt.show()\n",
    "\n",
    "importances = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "importances[:10].plot(kind='barh')\n",
    "plt.title('Top 10 Vari√°veis mais Importantes - Random Forest')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
